<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>YoloBaseNode | ConcaXu</title><meta name="author" content="Conca Xu"><meta name="copyright" content="Conca Xu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="​目录 Yolo的任务分类Yolo的模式类型Yolo的任务分类Train（训练）概念demofrom ultralytics import YOLO​ Load a modelmodel &#x3D; YOLO(“yolov8n.yaml”)  # build a new model from YAMLmodel &#x3D; YOLO(“yolov8n.pt”)  # load a pretra">
<meta property="og:type" content="article">
<meta property="og:title" content="YoloBaseNode">
<meta property="og:url" content="https://username.github.io/project/2024/07/18/YoloBaseNode/index.html">
<meta property="og:site_name" content="ConcaXu">
<meta property="og:description" content="​目录 Yolo的任务分类Yolo的模式类型Yolo的任务分类Train（训练）概念demofrom ultralytics import YOLO​ Load a modelmodel &#x3D; YOLO(“yolov8n.yaml”)  # build a new model from YAMLmodel &#x3D; YOLO(“yolov8n.pt”)  # load a pretra">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://avatars.githubusercontent.com/u/71932317?s=400&u=83d5623cc2765fe5ff750187329448f1efc2b506&v=4">
<meta property="article:published_time" content="2024-07-18T06:38:36.000Z">
<meta property="article:modified_time" content="2024-07-18T06:48:51.664Z">
<meta property="article:author" content="Conca Xu">
<meta property="article:tag" content="node.js">
<meta property="article:tag" content="hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://avatars.githubusercontent.com/u/71932317?s=400&u=83d5623cc2765fe5ff750187329448f1efc2b506&v=4"><link rel="shortcut icon" href="/project/img/favicon.png"><link rel="canonical" href="https://username.github.io/project/2024/07/18/YoloBaseNode/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/project/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/project/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'YoloBaseNode',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-07-18 14:48:51'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/modify.css"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/project/atom.xml" title="ConcaXu" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://avatars.githubusercontent.com/u/71932317?s=400&amp;u=83d5623cc2765fe5ff750187329448f1efc2b506&amp;v=4" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/project/archives/"><div class="headline">文章</div><div class="length-num">2</div></a><a href="/project/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/project/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://images.pexels.com/photos/1429567/pexels-photo-1429567.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=1')"><nav id="nav"><span id="blog-info"><a href="/project/" title="ConcaXu"><span class="site-name">ConcaXu</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">YoloBaseNode</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-07-18T06:38:36.000Z" title="发表于 2024-07-18 14:38:36">2024-07-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-07-18T06:48:51.664Z" title="更新于 2024-07-18 14:48:51">2024-07-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/project/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="YoloBaseNode"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>​<br>目录</p>
<h3 id="Yolo的任务分类"><a href="#Yolo的任务分类" class="headerlink" title="Yolo的任务分类"></a>Yolo的任务分类</h3><h3 id="Yolo的模式类型"><a href="#Yolo的模式类型" class="headerlink" title="Yolo的模式类型"></a>Yolo的模式类型</h3><h3 id="Yolo的任务分类-1"><a href="#Yolo的任务分类-1" class="headerlink" title="Yolo的任务分类"></a>Yolo的任务分类</h3><h3 id="Train（训练）"><a href="#Train（训练）" class="headerlink" title="Train（训练）"></a>Train（训练）</h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>demo<br>from ultralytics import YOLO<br>​</p>
<h1 id="Load-a-model"><a href="#Load-a-model" class="headerlink" title="Load a model"></a>Load a model</h1><p>model &#x3D; YOLO(“yolov8n.yaml”)  # build a new model from YAML<br>model &#x3D; YOLO(“yolov8n.pt”)  # load a pretrained model (recommended for training)<br>model &#x3D; YOLO(“yolov8n.yaml”).load(“yolov8n.pt”)  # build from YAML and transfer weights<br>​</p>
<h1 id="Train-the-model"><a href="#Train-the-model" class="headerlink" title="Train the model"></a>Train the model</h1><p>results &#x3D; model.train(data&#x3D;”coco8.yaml”, epochs&#x3D;100, imgsz&#x3D;640)<br>参数<br>参数	默认值	说明<br>model	None	指定用于训练的模型文件。接受指向 .pt 预训练模型或 .yaml 配置文件。对于定义模型结构或初始化权重至关重要。<br>data	None	数据集配置文件的路径（例如 coco8.yaml).该文件包含特定于数据集的参数，包括训练数据和验证数据的路径、类名和类数。<br>epochs	100	训练历元总数。每个历元代表对整个数据集进行一次完整的训练。调整该值会影响训练时间和模型性能。<br>time	None	最长训练时间（小时）。如果设置了该值，则会覆盖 epochs 参数，允许训练在指定的持续时间后自动停止。对于时间有限的训练场景非常有用。<br>patience	100	在验证指标没有改善的情况下，提前停止训练所需的历元数。当性能趋于平稳时停止训练，有助于防止过度拟合。<br>batch	16	训练的批量大小，表示在更新模型内部参数之前要处理多少张图像。自动批处理 (batch&#x3D;-1)会根据 GPU 内存可用性动态调整批处理大小。<br>imgsz	640	用于训练的目标图像尺寸。所有图像在输入模型前都会被调整到这一尺寸。影响模型精度和计算复杂度。<br>save	True	可保存训练检查点和最终模型权重。这对恢复训练或模型部署非常有用。<br>save_period	-1	保存模型检查点的频率，以 epochs 为单位。值为-1 时将禁用此功能。该功能适用于在长时间训练过程中保存临时模型。<br>cache	False	在内存中缓存数据集图像 (True&#x2F;ram）、磁盘 (disk），或禁用它 (False).通过减少磁盘 I&#x2F;O 提高训练速度，但代价是增加内存使用量。<br>device	None	指定用于训练的计算设备：单个 GPU (device&#x3D;0）、多个 GPU (device&#x3D;0,1)、CPU (device&#x3D;cpu)，或苹果芯片的 MPS (device&#x3D;mps).<br>workers	8	加载数据的工作线程数（每 RANK 多 GPU 训练）。影响数据预处理和输入模型的速度，尤其适用于多 GPU 设置。<br>project	None	保存训练结果的项目目录名称。允许有组织地存储不同的实验。<br>name	None	训练运行的名称。用于在项目文件夹内创建一个子目录，用于存储训练日志和输出结果。<br>exist_ok	False	如果为 True，则允许覆盖现有的项目&#x2F;名称目录。这对迭代实验非常有用，无需手动清除之前的输出。<br>pretrained	True	决定是否从预处理模型开始训练。可以是布尔值，也可以是加载权重的特定模型的字符串路径。提高训练效率和模型性能。<br>optimizer	‘auto’	为培训选择优化器。选项包括 SGD, Adam, AdamW, NAdam, RAdam, RMSProp 等，或 auto 用于根据模型配置进行自动选择。影响收敛速度和稳定性<br>verbose	False	在训练过程中启用冗长输出，提供详细日志和进度更新。有助于调试和密切监控培训过程。<br>seed	0	为训练设置随机种子，确保在相同配置下运行的结果具有可重复性。<br>deterministic	True	强制使用确定性算法，确保可重复性，但由于对非确定性算法的限制，可能会影响性能和速度。<br>single_cls	False	在训练过程中将多类数据集中的所有类别视为单一类别。适用于二元分类任务，或侧重于对象的存在而非分类。<br>rect	False	可进行矩形训练，优化批次组成以减少填充。这可以提高效率和速度，但可能会影响模型的准确性。<br>cos_lr	False	利用余弦学习率调度器，根据历时的余弦曲线调整学习率。这有助于管理学习率，实现更好的收敛。<br>close_mosaic	10	在训练完成前禁用最后 N 个历元的马赛克数据增强以稳定训练。设置为 0 则禁用此功能。<br>resume	False	从上次保存的检查点恢复训练。自动加载模型权重、优化器状态和历时计数，无缝继续训练。<br>amp	True	启用自动混合精度 (AMP) 训练，可减少内存使用量并加快训练速度，同时将对精度的影响降至最低。<br>fraction	1.0	指定用于训练的数据集的部分。允许在完整数据集的子集上进行训练，这对实验或资源有限的情况非常有用。<br>profile	False	在训练过程中，可对ONNX 和TensorRT 速度进行剖析，有助于优化模型部署。<br>freeze	None	冻结模型的前 N 层或按索引指定的层，从而减少可训练参数的数量。这对微调或迁移学习非常有用。<br>lr0	0.01	初始学习率（即 SGD&#x3D;1E-2, Adam&#x3D;1E-3) .调整这个值对优化过程至关重要，会影响模型权重的更新速度。<br>lrf	0.01	最终学习率占初始学习率的百分比 &#x3D; (lr0 * lrf)，与调度程序结合使用，随着时间的推移调整学习率。<br>momentum	0.937	用于 SGD 的动量因子，或用于 Adam 优化器的 beta1，用于将过去的梯度纳入当前更新。<br>weight_decay	0.0005	L2 正则化项，对大权重进行惩罚，以防止过度拟合。<br>warmup_epochs	3.0	学习率预热的历元数，学习率从低值逐渐增加到初始学习率，以在早期稳定训练。<br>warmup_momentum	0.8	热身阶段的初始动力，在热身期间逐渐调整到设定动力。<br>warmup_bias_lr	0.1	热身阶段的偏置参数学习率，有助于稳定初始历元的模型训练。<br>box	7.5	损失函数中边框损失部分的权重，影响对准确预测边框坐标的重视程度。<br>cls	0.5	分类损失在总损失函数中的权重，影响正确分类预测相对于其他部分的重要性。<br>dfl	1.5	分布焦点损失权重，在某些YOLO 版本中用于精细分类。<br>pose	12.0	姿态损失在姿态估计模型中的权重，影响着准确预测姿态关键点的重点。<br>kobj	2.0	姿态估计模型中关键点对象性损失的权重，平衡检测可信度与姿态精度。<br>label_smoothing	0.0	应用标签平滑，将硬标签软化为目标标签和标签均匀分布的混合标签，可以提高泛化效果。<br>nbs	64	用于损耗正常化的标称批量大小。<br>overlap_mask	True	决定在训练过程中分割掩码是否应该重叠，适用于实例分割任务。<br>mask_ratio	4	分割掩码的下采样率，影响训练时使用的掩码分辨率。<br>dropout	0.0	分类任务中正则化的丢弃率，通过在训练过程中随机省略单元来防止过拟合。<br>val	True	可在训练过程中进行验证，以便在单独的数据集上对模型性能进行定期评估。<br>plots	False	生成并保存训练和验证指标图以及预测示例图，以便直观地了解模型性能和学习进度。<br>​</p>
<p>超参数<br>参数名	类型	默认值	范围	说明<br>hsv_h	float	0.015	0.0 - 1.0	通过色轮的一部分来调整图像的色调，从而引入色彩的可变性。帮助模型在不同的光照条件下通用。<br>hsv_s	float	0.7	0.0 - 1.0	改变图像饱和度的一部分，影响色彩的强度。可用于模拟不同的环境条件。<br>hsv_v	float	0.4	0.0 - 1.0	将图像的数值（亮度）修改一部分，帮助模型在不同的光照条件下表现良好。<br>degrees	float	0.0	-180 - +180	在指定的度数范围内随机旋转图像，提高模型识别不同方向物体的能力。<br>translate	float	0.1	0.0 - 1.0	以图像大小的一小部分水平和垂直平移图像，帮助学习检测部分可见的物体。<br>scale	float	0.5	&gt;&#x3D;0.0	通过增益因子缩放图像，模拟物体与摄像机的不同距离。<br>shear	float	0.0	-180 - +180	按指定角度剪切图像，模拟从不同角度观察物体的效果。<br>perspective	float	0.0	0.0 - 0.001	对图像进行随机透视变换，增强模型理解三维空间中物体的能力。<br>flipud	float	0.0	0.0 - 1.0	以指定的概率将图像翻转过来，在不影响物体特征的情况下增加数据的可变性。<br>fliplr	float	0.5	0.0 - 1.0	以指定的概率将图像从左到右翻转，这对学习对称物体和增加数据集多样性非常有用。<br>bgr	float	0.0	0.0 - 1.0	以指定的概率将图像通道从 RGB 翻转到 BGR，用于提高对错误通道排序的稳健性。<br>mosaic	float	1.0	0.0 - 1.0	将四幅训练图像合成一幅，模拟不同的场景构成和物体互动。对复杂场景的理解非常有效。<br>mixup	float	0.0	0.0 - 1.0	混合两幅图像及其标签，创建合成图像。通过引入标签噪声和视觉变化，增强模型的泛化能力。<br>copy_paste	float	0.0	0.0 - 1.0	从一幅图像中复制物体并粘贴到另一幅图像上，用于增加物体实例和学习物体遮挡。<br>auto_augment	str	randaugment	-	自动应用预定义的增强策略 (randaugment, autoaugment, augmix)，通过丰富视觉特征来优化分类任务。<br>erasing	float	0.4	0.0 - 0.9	在分类训练过程中随机擦除部分图像，鼓励模型将识别重点放在不明显的特征上。<br>crop_fraction	float	1.0	0.1 - 1.0	将分类图像裁剪为其大小的一小部分，以突出中心特征并适应对象比例，减少背景干扰。<br>​</p>
<p>常用参数<br>epoch、 imgsz、 save、 device、 workers<br>Val（评估）<br>概念</p>
<p>demo<br>from ultralytics import YOLO<br>​</p>
<h1 id="Load-a-model-1"><a href="#Load-a-model-1" class="headerlink" title="Load a model"></a>Load a model</h1><p>model &#x3D; YOLO(“yolov8n.pt”)  # load an official model<br>model &#x3D; YOLO(“path&#x2F;to&#x2F;best.pt”)  # load a custom model<br>​</p>
<h1 id="Validate-the-model"><a href="#Validate-the-model" class="headerlink" title="Validate the model"></a>Validate the model</h1><p>metrics &#x3D; model.val()  # no arguments needed, dataset and settings remembered<br>metrics.box.map  # map50-95<br>metrics.box.map50  # map50<br>metrics.box.map75  # map75<br>metrics.box.maps  # a list contains map50-95 of each category<br>参数&#x2F;超参数<br>参数	类型	默认值	说明<br>data	str	None	指定数据集配置文件的路径（如 coco8.yaml).该文件包括验证数据的路径、类名和类数。<br>imgsz	int	640	定义输入图像的尺寸。所有图像在处理前都会调整到这一尺寸。<br>batch	int	16	设置每批图像的数量。使用 -1 的自动批处理功能，可根据 GPU 内存可用性自动调整。<br>save_json	bool	False	如果 True此外，还可将结果保存到 JSON 文件中，以便进一步分析或与其他工具集成。<br>save_hybrid	bool	False	如果 True，保存混合版本的标签，将原始注释与额外的模型预测相结合。<br>conf	float	0.001	设置检测的最小置信度阈值。置信度低于此阈值的检测将被丢弃。<br>iou	float	0.6	设置非最大抑制 (NMS) 的交叉重叠 (IoU) 阈值。有助于减少重复检测。<br>max_det	int	300	限制每幅图像的最大检测次数。在密度较高的场景中非常有用，可以防止检测次数过多。<br>half	bool	True	可进行半精度（FP16）计算，减少内存使用量，在提高速度的同时，将对精度的影响降至最低。<br>device	str	None	指定验证设备 (cpu, cuda:0等）。可灵活利用 CPU 或 GPU 资源。<br>dnn	bool	False	如果 True它使用 OpenCV DNN 模块进行ONNX 模型推断，为PyTorch 推断方法提供了一种替代方法。<br>plots	bool	False	当设置为 True此外，它还能生成并保存预测结果与地面实况的对比图，以便对模型的性能进行可视化评估。<br>rect	bool	False	如果 True该软件使用矩形推理进行批处理，减少了填充，可能会提高速度和效率。<br>split	str	val	确定用于验证的数据集分割 (val, test或 train).可灵活选择数据段进行性能评估。<br>​</p>
<p>常用参数<br>batch 、 conf、 IoU、 half<br>Predict(预测)<br>demo<br>from ultralytics import YOLO<br>​</p>
<h1 id="Load-a-pretrained-YOLOv8n-model"><a href="#Load-a-pretrained-YOLOv8n-model" class="headerlink" title="Load a pretrained YOLOv8n model"></a>Load a pretrained YOLOv8n model</h1><p>model &#x3D; YOLO(“yolov8n.pt”)<br>​</p>
<h1 id="Run-inference-on-‘bus-jpg’-with-arguments"><a href="#Run-inference-on-‘bus-jpg’-with-arguments" class="headerlink" title="Run inference on ‘bus.jpg’ with arguments"></a>Run inference on ‘bus.jpg’ with arguments</h1><p>result &#x3D; model.predict(“bus.jpg”, save&#x3D;True, imgsz&#x3D;320, conf&#x3D;0.5)</p>
<h1 id="Value-of-result"><a href="#Value-of-result" class="headerlink" title="Value of result"></a>Value of result</h1><p>for result in results:<br>    print(“图像原始大小:”, result.orig_shape)<br>    data_numpy &#x3D; result.boxes.data.cpu().numpy()<br>    for data in data_numpy:<br>        print(“data”, data)<br>        print(“左上角X轴坐标:”, data[0])<br>        print(“左上角Y轴坐标:”, data[1])<br>        print(“右下角X轴坐标:”, data[2])<br>        print(“右下角Y轴坐标:”, data[3])<br>        print(“置—信—度:”, data[4])<br>        print(“检测到的类有:”,  data[5])</p>
<p>参数<br>论据	类型	默认值	说明<br>source	str	‘ultralytics&#x2F;assets’	指定推理的数据源。可以是图像路径、视频文件、目录、URL 或用于实时馈送的设备 ID。支持多种格式和来源，可灵活应用于不同类型的输入。<br>conf	float	0.25	设置检测的最小置信度阈值。如果检测到的对象置信度低于此阈值，则将不予考虑。调整该值有助于减少误报。<br>iou	float	0.7	非最大抑制 (NMS) 的交叉重叠 (IoU) 阈值。较低的数值可以消除重叠的方框，从而减少检测次数，这对减少重复检测非常有用。<br>imgsz	int or tuple	640	定义用于推理的图像大小。可以是一个整数 640 或一个（高、宽）元组。适当调整大小可以提高检测精度和处理速度。<br>half	bool	False	启用半精度（FP16）推理，可加快支持的 GPU 上的模型推理速度，同时将对精度的影响降至最低。<br>device	str	None	指定用于推理的设备（例如：……）、 cpu, cuda:0 或 0).允许用户选择 CPU、特定 GPU 或其他计算设备来执行模型。<br>max_det	int	300	每幅图像允许的最大检测次数。限制模型在单次推理中可检测到的物体总数，防止在密集场景中产生过多输出。<br>vid_stride	int	1	视频输入的帧间距。允许跳过视频中的帧，以加快处理速度，但会牺牲时间分辨率。值为 1 时处理每一帧，值越大跳帧越多。<br>stream_buffer	bool	False	确定在处理视频流时是否对所有帧进行缓冲 (True)，或者模型是否应该返回最近的帧 (False).适用于实时应用。<br>visualize	bool	False	在推理过程中激活模型特征的可视化，从而深入了解模型 “看到 “了什么。这对调试和模型解释非常有用。<br>augment	bool	False	可对预测进行测试时间增强（TTA），从而在牺牲推理速度的情况下提高检测的鲁棒性。<br>agnostic_nms	bool	False	启用与类别无关的非最大抑制 (NMS)，可合并不同类别的重叠方框。这在多类检测场景中非常有用，因为在这种场景中，类的重叠很常见。<br>classes	list[int]	None	根据一组类别 ID 过滤预测结果。只返回属于指定类别的检测结果。在多类检测任务中，该功能有助于集中检测相关对象。<br>retina_masks	bool	False	如果模型中存在高分辨率的分割掩膜，则使用高分辨率的分割掩膜。这可以提高分割任务的掩膜质量，提供更精细的细节。<br>embed	list[int]	None	指定从中提取特征向量或嵌入的层。这对聚类或相似性搜索等下游任务非常有用。<br>​</p>
<p>常用参数<br>conf、 IoU、 half、 imgsz、 device、 classes、<br>结果参数<br>属性	类型	说明<br>orig_img	numpy.ndarray	原始图像的 numpy 数组。<br>orig_shape	tuple	原始图像的形状，格式为（高、宽）。<br>boxes	Boxes, optional	包含检测边界框的方框对象。<br>masks	Masks, optional	包含检测掩码的掩码对象。<br>probs	Probs, optional	Probs 对象，包含分类任务中每个类别的概率。<br>keypoints	Keypoints, optional	关键点对象，包含每个对象的检测关键点。<br>obb	OBB, optional	包含定向包围盒的 OBB 对象。<br>speed	dict	每幅图像的预处理、推理和后处理速度字典，单位为毫秒。<br>names	dict	类名字典。<br>path	str	图像文件的路径。<br>​</p>
<p>results支持方法<br>方法	返回类型	说明<br>update()	None	更新结果对象的方框、掩码和 probs 属性。<br>cpu()	Results	返回包含 CPU 内存中所有张量的结果对象副本。<br>numpy()	Results	返回结果对象的副本，其中所有张量均为 numpy 数组。<br>cuda()	Results	返回包含 GPU 内存中所有张量的 Results 对象副本。<br>to()	Results	返回带有指定设备和 dtype 上张量的 Results 对象副本。<br>new()	Results	返回一个具有相同图像、路径和名称的新结果对象。<br>plot()	numpy.ndarray	绘制检测结果。返回注释图像的 numpy 数组。<br>show()	None	在屏幕上显示带注释的结果。<br>save()	None	将注释结果保存到文件中。<br>verbose()	str	返回每个任务的日志字符串。<br>save_txt()	None	将预测结果保存到 txt 文件中。<br>save_crop()	None	将裁剪后的预测保存到 save_dir&#x2F;cls&#x2F;file_name.jpg.<br>tojson()	str	将对象转换为 JSON 格式。<br>​</p>
<p>Export（导出）</p>
<p>demo<br>from ultralytics import YOLO<br>​</p>
<h1 id="Load-a-model-2"><a href="#Load-a-model-2" class="headerlink" title="Load a model"></a>Load a model</h1><p>model &#x3D; YOLO(“yolov8n.pt”)  # load an official model<br>model &#x3D; YOLO(“path&#x2F;to&#x2F;best.pt”)  # load a custom trained model<br>​</p>
<h1 id="Export-the-model"><a href="#Export-the-model" class="headerlink" title="Export the model"></a>Export the model</h1><p>model.export(format&#x3D;”onnx”)<br>参数<br>论据	类型	默认值	说明<br>format	str	‘torchscript’	导出模型的目标格式，例如 ‘onnx’, ‘torchscript’, ‘tensorflow’或其他，定义与各种部署环境的兼容性。<br>imgsz	int 或 tuple	640	模型输入所需的图像尺寸。对于正方形图像，可以是一个整数，或者是一个元组 (height, width) 了解具体尺寸。<br>keras	bool	False	启用导出为 Keras 格式的TensorFlow SavedModel ，提供与TensorFlow serving 和 API 的兼容性。<br>optimize	bool	False	在导出到TorchScript 时，应用针对移动设备的优化，可能会减小模型大小并提高性能。<br>half	bool	False	启用 FP16（半精度）量化，在支持的硬件上减小模型大小并可能加快推理速度。<br>int8	bool	False	激活 INT8 量化，进一步压缩模型并加快推理速度，同时将精度损失降至最低，主要用于边缘设备。<br>dynamic	bool	False	允许ONNX 和TensorRT 导出动态输入尺寸，提高了处理不同图像尺寸的灵活性。<br>simplify	bool	False	简化了ONNX 导出的模型图，可能会提高性能和兼容性。<br>opset	int	None	指定ONNX opset 版本，以便与不同的ONNX 解析器和运行时兼容。如果未设置，则使用最新的支持版本。<br>workspace	float	4.0	为TensorRT 优化设置最大工作区大小（GiB），以平衡内存使用和性能。<br>nms	bool	False	在CoreML 导出中添加非最大值抑制 (NMS)，这对精确高效的检测后处理至关重要。<br>batch	int	1	指定导出模型的批量推理大小，或导出模型将同时处理的图像的最大数量。 predict 模式。<br>​</p>
<p>支持导出格式<br>​</p>
<p>格式	format 论据	模型	元数据	论据<br>PyTorch	-	yolov8n.pt	✅	-<br>TorchScript	torchscript	yolov8n.torchscript	✅	imgsz, optimize, batch<br>ONNX	onnx	yolov8n.onnx	✅	imgsz, half, dynamic, simplify, opset, batch<br>OpenVINO	openvino	yolov8n_openvino_model&#x2F;	✅	imgsz, half, int8, batch<br>TensorRT	engine	yolov8n.engine	✅	imgsz, half, dynamic, simplify, workspace, int8, batch<br>CoreML	coreml	yolov8n.mlpackage	✅	imgsz, half, int8, nms, batch<br>TF SavedModel	saved_model	yolov8n_saved_model&#x2F;	✅	imgsz, keras, int8, batch<br>TF GraphDef	pb	yolov8n.pb	❌	imgsz, batch<br>TF 轻型	tflite	yolov8n.tflite	✅	imgsz, half, int8, batch<br>TF 边缘TPU	edgetpu	yolov8n_edgetpu.tflite	✅	imgsz, batch<br>TF.js	tfjs	yolov8n_web_model&#x2F;	✅	imgsz, half, int8, batch<br>PaddlePaddle	paddle	yolov8n_paddle_model&#x2F;	✅	imgsz, batch<br>NCNN	ncnn	yolov8n_ncnn_model&#x2F;	✅	imgsz, half, batch<br>​</p>
<p>Yolo的模式类型<br>Detect（检测）</p>
<p>模型<br>​</p>
<p>模型	尺寸<br>（像素）	mAPval<br>50-95	速度<br>CPUONNX<br>(ms)	速度<br>A100 TensorRT<br>（毫秒）	params<br>(M)	FLOPs<br>(B)<br>YOLOv8n	640	37.3	80.4	0.99	3.2	8.7<br>YOLOv8s	640	44.9	128.4	1.20	11.2	28.6<br>YOLOv8m	640	50.2	234.7	1.83	25.9	78.9<br>YOLOv8l	640	52.9	375.2	2.39	43.7	165.2<br>YOLOv8x	640	53.9	479.1	3.53	68.2	257.8<br>​</p>
<p>Segment（分割）</p>
<p>模型<br>​</p>
<p>模型	尺寸<br>（像素）	mAPbox<br>50-95	mAPmask<br>50-95	速度<br>CPUONNX<br>(ms)	速度<br>A100 TensorRT<br>（毫秒）	params<br>(M)	FLOPs<br>(B)<br>YOLOv8n-seg	640	36.7	30.5	96.1	1.21	3.4	12.6<br>YOLOv8s-seg	640	44.6	36.8	155.7	1.47	11.8	42.6<br>YOLOv8m-seg	640	49.9	40.8	317.0	2.18	27.3	110.2<br>YOLOv8l-seg	640	52.3	42.6	572.4	2.79	46.0	220.5<br>YOLOv8x-seg	640	53.4	43.4	712.1	4.02	71.8	344.1<br>​</p>
<p>Classify（分类）</p>
<p>模型<br>​</p>
<p>模型	尺寸<br>（像素）	acc<br>top1	acc<br>top5	速度<br>CPUONNX<br>(ms)	速度<br>A100 TensorRT<br>（毫秒）	params<br>(M)	FLOPs<br>(B) at 640<br>YOLOv8n-cls	224	69.0	88.3	12.9	0.31	2.7	4.3<br>YOLOv8s-cls	224	73.8	91.7	23.4	0.35	6.4	13.5<br>YOLOv8m-cls	224	76.8	93.5	85.4	0.62	17.0	42.7<br>YOLOv8l-cls	224	76.8	93.5	163.0	0.87	37.5	99.7<br>YOLOv8x-cls	224	79.0	94.6	232.0	1.01	57.4	154.8<br>​</p>
<p>Pose（姿态）</p>
<p>模型<br>​</p>
<p>模型	尺寸<br>（像素）<br>50-95	mAPpose<br>50	速度<br>CPUONNX<br>(ms)	速度<br>A100 TensorRT<br>（毫秒）	params<br>(M)	FLOPs<br>(B)<br>YOLOv8n-姿势	640	50.4	80.1	131.8	1.18	3.3	9.2<br>YOLOv8s-姿势	640	60.0	86.2	233.2	1.42	11.6	30.2<br>YOLOv8m-姿势	640	65.0	88.8	456.3	2.00	26.4	81.0<br>YOLOv8l-姿势	640	67.6	90.0	784.5	2.59	44.4	168.6<br>YOLOv8x-姿势	640	69.2	90.2	1607.1	3.73	69.4	263.2<br>YOLOv8x-pose-p6	1280	71.6	91.2	4088.7	10.04	99.1	1066.4<br>​</p>
<p>OBB（定向检测）</p>
<p>模型<br>模型	尺寸<br>（像素）	mAPtest<br>50	速度<br>CPUONNX<br>(ms)	速度<br>A100 TensorRT<br>（毫秒）	params<br>(M)	FLOPs<br>(B)<br>YOLOv8n-obb	1024	78.0	204.77	3.57	3.1	23.3<br>YOLOv8s-obb	1024	79.5	424.88	4.07	11.4	76.3<br>YOLOv8m-obb	1024	80.5	763.48	7.61	26.4	208.6<br>YOLOv8l-obb	1024	80.7	1278.42	11.83	44.5	433.8<br>YOLOv8x-obb	1024	81.36	1759.10	13.23	69.5	676.7<br>​</p>
<p>个人经验<br>如何使用Yolov8</p>
<p>pip install ultralytics<br>pip3 install torch torchvision torchaudio –index-url <a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/cu118">https://download.pytorch.org/whl/cu118</a> (根据自己电脑配置决定)</p>
<p>nvidia-smi 查看自己电脑支持的最高cuda版本，建议安装11.8比较稳定<br>然后安装对应支持的cuda，cudnn<br>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/jhsignal/article/details/111401628">https://blog.csdn.net/jhsignal/article/details/111401628</a></p>
<p>import torch<br>print(torch.cuda.is_available())<br>x &#x3D; torch.rand(5, 5).cuda()<br>print(x)<br>训练结果参数理解</p>
<p>训练自己的数据集</p>
<p>path: D:\PythonProject\ultralytics\datasets\myselfData # dataset中的文件夹路径<br>train: images&#x2F;train2017 # train images 训练的图片路径<br>val: images&#x2F;train2017 # val images 验证的图片路径<br>test: images&#x2F;train2017 # test images 测试的图片路径</p>
<h1 id="Classes"><a href="#Classes" class="headerlink" title="Classes"></a>Classes</h1><p>names:<br>0: Bread<br>1: Paper<br>2: People<br>启动训练函数<br>from ultralytics import YOLO</p>
<p>def train():</p>
<h1 id="确保配置文件是正确的，通常是与预训练模型相同的配置文件"><a href="#确保配置文件是正确的，通常是与预训练模型相同的配置文件" class="headerlink" title="确保配置文件是正确的，通常是与预训练模型相同的配置文件"></a>确保配置文件是正确的，通常是与预训练模型相同的配置文件</h1><p>model &#x3D; YOLO(‘yolov8m.yaml’).load(‘yolov8n.pt’)</p>
<pre><code># 开始训练模型
results = model.train(data=&#39;datasets/myselfData/myselfData.yaml&#39;, epochs=300, batch=16, device=0, workers=8, imgsz=640) 
return results
</code></pre>
<p>if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘:<br>results &#x3D; train()<br>预测函数<br>import os</p>
<p>import cv2<br>import numpy as np<br>from ultralytics import YOLO</p>
<p>model &#x3D; YOLO(‘..&#x2F;yolopt&#x2F;best.pt’)<br>folder_path &#x3D; “D:&#x2F;PythonProject&#x2F;xxx” #可以使用绝对路径&#x2F;相对路径，文件夹图片都可以放<br>results &#x3D; model.predict(folder_path, save&#x3D;True, imgsz&#x3D;320, conf&#x3D;0.5, device&#x3D;’0’, half&#x3D;True)<br>for result in results:<br>data_numpy &#x3D; result.boxes.data.cpu().numpy()<br>for data in data_numpy:<br>print(“左上角X轴坐标:”, data[0])<br>print(“左上角Y轴坐标:”, data[1])<br>print(“右下角X轴坐标:”, data[2])<br>print(“右下角Y轴坐标:”, data[3])<br>print(“置—信—度:”, data[4])<br>print(“检测到的类有:”, [int(data[5])])<br>验证函数<br>from ultralytics import YOLO</p>
<p>def val():<br>model &#x3D; YOLO(“..&#x2F;bestX.pt”)<br>validation_results &#x3D; model.val(data&#x3D;”datasets&#x2F;myselfData&#x2F;myselfData.yaml”, imgsz&#x3D;640,<br>batch&#x3D;64, conf&#x3D;0.5, iou&#x3D;0.6, device&#x3D;”0”)</p>
<p>if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘:<br>val()<br>模型转换（Pt转Onnx）<br>import cv2<br>import torch</p>
<p>from tensor_rt.main import YOLOv8<br>from ultralytics import YOLO</p>
<h1 id="Pt转换Onnx模型"><a href="#Pt转换Onnx模型" class="headerlink" title="# Pt转换Onnx模型"></a># Pt转换Onnx模型</h1><p>device &#x3D; “cuda:0” if torch.cuda.is_available() else “cpu”<br>onnx_model &#x3D; YOLO(“DarkPointX.onnx”)<br>results &#x3D; onnx_model(“202404201048220.jpg”)<br>print(results)<br> 模型（Pt转Engine）<br>from ultralytics import YOLO<br>import torch</p>
<h1 id="检查GPU是否可用，并设置为默认设备"><a href="#检查GPU是否可用，并设置为默认设备" class="headerlink" title="检查GPU是否可用，并设置为默认设备"></a>检查GPU是否可用，并设置为默认设备</h1><p>device &#x3D; ‘cuda’ if torch.cuda.is_available() else ‘cpu’<br>print(f”Using device: {device}”)</p>
<h1 id="载入模型并转移到设备"><a href="#载入模型并转移到设备" class="headerlink" title="载入模型并转移到设备"></a>载入模型并转移到设备</h1><p>model &#x3D; YOLO(“DarkPointX.pt”).to(device)<br>model.export(<br>format&#x3D;”engine”,<br>dynamic&#x3D;True,<br>batch&#x3D;32,<br>workspace&#x3D;4,<br>half&#x3D;True,<br>data&#x3D;”bread.yaml”,<br>)<br>print(“Done”)</p>
<h1 id="results-self-model-predict-image-save-False-imgsz-640-conf-self-conf-device-’0’-half-True"><a href="#results-self-model-predict-image-save-False-imgsz-640-conf-self-conf-device-’0’-half-True" class="headerlink" title="results &#x3D; self.model.predict(image, save&#x3D;False, imgsz&#x3D;640, conf&#x3D;self.conf, device&#x3D;’0’, half&#x3D;True)"></a>results &#x3D; self.model.predict(image, save&#x3D;False, imgsz&#x3D;640, conf&#x3D;self.conf, device&#x3D;’0’, half&#x3D;True)</h1><h1 id="Load-the-exported-TensorRT-INT8-model"><a href="#Load-the-exported-TensorRT-INT8-model" class="headerlink" title="Load the exported TensorRT INT8 model"></a>Load the exported TensorRT INT8 model</h1><p>model &#x3D; YOLO(“DarkPointX.engine”)</p>
<h1 id="Run-inference"><a href="#Run-inference" class="headerlink" title="Run inference"></a>Run inference</h1><p>result &#x3D; model.predict(“<a target="_blank" rel="noopener" href="https://ultralytics.com/images/bus.jpg">https://ultralytics.com/images/bus.jpg</a>“)</p>
<p>​</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://username.github.io/project">Conca Xu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://username.github.io/project/2024/07/18/YoloBaseNode/">https://username.github.io/project/2024/07/18/YoloBaseNode/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://username.github.io/project" target="_blank">ConcaXu</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/project/tags/node-js/">node.js</a><a class="post-meta__tags" href="/project/tags/hexo/">hexo</a></div><div class="post_share"><div class="social-share" data-image="https://avatars.githubusercontent.com/u/71932317?s=400&amp;u=83d5623cc2765fe5ff750187329448f1efc2b506&amp;v=4" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/project/2024/04/07/hello-world/" title="Hello World"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Hello World</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/project/2024/04/07/hello-world/" title="Hello World"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-07</div><div class="title">Hello World</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://avatars.githubusercontent.com/u/71932317?s=400&amp;u=83d5623cc2765fe5ff750187329448f1efc2b506&amp;v=4" onerror="this.onerror=null;this.src='/project/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Conca Xu</div><div class="author-info__description">This is Conca Xu</div></div><div class="card-info-data site-data is-center"><a href="/project/archives/"><div class="headline">文章</div><div class="length-num">2</div></a><a href="/project/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/project/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ConcaXu"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Yolo%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%88%86%E7%B1%BB"><span class="toc-number">1.</span> <span class="toc-text">Yolo的任务分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Yolo%E7%9A%84%E6%A8%A1%E5%BC%8F%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.</span> <span class="toc-text">Yolo的模式类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Yolo%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%88%86%E7%B1%BB-1"><span class="toc-number">3.</span> <span class="toc-text">Yolo的任务分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Train%EF%BC%88%E8%AE%AD%E7%BB%83%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">Train（训练）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5"><span class="toc-number">4.1.</span> <span class="toc-text">概念</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Load-a-model"><span class="toc-number"></span> <span class="toc-text">Load a model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Train-the-model"><span class="toc-number"></span> <span class="toc-text">Train the model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Load-a-model-1"><span class="toc-number"></span> <span class="toc-text">Load a model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Validate-the-model"><span class="toc-number"></span> <span class="toc-text">Validate the model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Load-a-pretrained-YOLOv8n-model"><span class="toc-number"></span> <span class="toc-text">Load a pretrained YOLOv8n model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Run-inference-on-%E2%80%98bus-jpg%E2%80%99-with-arguments"><span class="toc-number"></span> <span class="toc-text">Run inference on ‘bus.jpg’ with arguments</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Value-of-result"><span class="toc-number"></span> <span class="toc-text">Value of result</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Load-a-model-2"><span class="toc-number"></span> <span class="toc-text">Load a model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Export-the-model"><span class="toc-number"></span> <span class="toc-text">Export the model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Classes"><span class="toc-number"></span> <span class="toc-text">Classes</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A1%AE%E4%BF%9D%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%98%AF%E6%AD%A3%E7%A1%AE%E7%9A%84%EF%BC%8C%E9%80%9A%E5%B8%B8%E6%98%AF%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%90%8C%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number"></span> <span class="toc-text">确保配置文件是正确的，通常是与预训练模型相同的配置文件</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Pt%E8%BD%AC%E6%8D%A2Onnx%E6%A8%A1%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text"># Pt转换Onnx模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5GPU%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8%EF%BC%8C%E5%B9%B6%E8%AE%BE%E7%BD%AE%E4%B8%BA%E9%BB%98%E8%AE%A4%E8%AE%BE%E5%A4%87"><span class="toc-number"></span> <span class="toc-text">检查GPU是否可用，并设置为默认设备</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BD%BD%E5%85%A5%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%BD%AC%E7%A7%BB%E5%88%B0%E8%AE%BE%E5%A4%87"><span class="toc-number"></span> <span class="toc-text">载入模型并转移到设备</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#results-self-model-predict-image-save-False-imgsz-640-conf-self-conf-device-%E2%80%990%E2%80%99-half-True"><span class="toc-number"></span> <span class="toc-text">results &#x3D; self.model.predict(image, save&#x3D;False, imgsz&#x3D;640, conf&#x3D;self.conf, device&#x3D;’0’, half&#x3D;True)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Load-the-exported-TensorRT-INT8-model"><span class="toc-number"></span> <span class="toc-text">Load the exported TensorRT INT8 model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Run-inference"><span class="toc-number"></span> <span class="toc-text">Run inference</span></a></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/project/2024/07/18/YoloBaseNode/" title="YoloBaseNode">YoloBaseNode</a><time datetime="2024-07-18T06:38:36.000Z" title="发表于 2024-07-18 14:38:36">2024-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/project/2024/04/07/hello-world/" title="Hello World">Hello World</a><time datetime="2024-04-06T16:38:36.000Z" title="发表于 2024-04-07 00:38:36">2024-04-07</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Conca Xu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/project/js/utils.js?v=4.13.0"></script><script src="/project/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>